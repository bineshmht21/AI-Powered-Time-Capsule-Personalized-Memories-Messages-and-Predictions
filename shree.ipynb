{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44f93dee-b7af-44cc-b387-f545e17686c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n",
      "Path to dataset files: C:\\Users\\BineshMahato\\.cache\\kagglehub\\datasets\\mexwell\\famous-birthdays\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mexwell/famous-birthdays\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d30f5a6-5754-42b9-9e80-f42c085be5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89ad59d090241edb8a89b0cfcda588e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='image/*', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Upload image widget (hidden initially)\n",
    "upload = widgets.FileUpload(\n",
    "    accept='image/*',  # Accept only images\n",
    "    multiple=False  # Allow single file upload\n",
    ")\n",
    "\n",
    "# Display widget\n",
    "display(upload)\n",
    "\n",
    "# Function to process the uploaded image\n",
    "def on_upload_change(change):\n",
    "    # Ensure a file was uploaded\n",
    "    if upload.value:\n",
    "        # Get the uploaded image (the file is in a dictionary)\n",
    "        file_info = upload.value[0]\n",
    "        image_data = file_info['content']\n",
    "        \n",
    "        # Convert bytes to a PIL Image object\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "        \n",
    "        # Optionally: Display the image\n",
    "        image.show()\n",
    "        \n",
    "        # You can now pass the image to a model for emotion detection, age estimation, etc.\n",
    "        # For example:\n",
    "        # emotion = detect_emotion(image)\n",
    "        # age = estimate_age(image)\n",
    "        # You could use the emotion or age to adjust your message generation logic\n",
    "\n",
    "        # For demonstration, let's print the file name\n",
    "        print(f\"Uploaded image: {file_info['metadata']['name']}\")\n",
    "        \n",
    "        # You could also pass this image to a model for further analysis (e.g., emotion recognition, age prediction)\n",
    "\n",
    "# Set the callback function to run when an image is uploaded\n",
    "upload.observe(on_upload_change, names='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cbf58438-8898-41c8-9e7c-e173885a4c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ded0b68260e427f858b9bc305f6e2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Select Image to Upload', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2db9ed6a77046d29732b6d648541fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='image/*', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9809e508b754f038ee6b5e4f4fb8009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, bar_style='info', description='Uploading:', style=ProgressStyle(description_width='initiaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "# Directory to save uploaded files\n",
    "upload_directory = 'uploaded_images'\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists(upload_directory):\n",
    "    os.makedirs(upload_directory)\n",
    "\n",
    "# Upload image widget (hidden initially)\n",
    "upload = widgets.FileUpload(\n",
    "    accept='image/*',  # Accept only images\n",
    "    multiple=False  # Allow single file upload\n",
    ")\n",
    "\n",
    "# Upload button to trigger file selection\n",
    "upload_button = widgets.Button(description=\"Select Image to Upload\")\n",
    "\n",
    "# Loading bar widget\n",
    "loading_bar = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description='Uploading:',\n",
    "    bar_style='info',  # can be 'success', 'info', 'warning', 'danger'\n",
    "    style={'description_width': 'initial'},\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "# Function to show the file upload widget when the button is clicked\n",
    "def on_upload_button_click(b):\n",
    "    # Show the file upload widget\n",
    "    upload.layout.visibility = 'visible'  \n",
    "    # Hide the upload button after it's clicked\n",
    "    upload_button.layout.visibility = 'hidden'  \n",
    "\n",
    "# Bind the button click event\n",
    "upload_button.on_click(on_upload_button_click)\n",
    "\n",
    "# Function to save and display the uploaded file details\n",
    "def save_uploaded_file(change):\n",
    "    # Check if a file is uploaded\n",
    "    uploaded_file = upload.value\n",
    "    if uploaded_file:\n",
    "        # Debugging: Print the entire structure of the uploaded file\n",
    "        print(\"Debug: Uploaded File Structure:\", uploaded_file)\n",
    "\n",
    "        # The `upload.value` can be a list or tuple in some cases, so we handle both cases\n",
    "        if isinstance(uploaded_file, tuple):\n",
    "            uploaded_file = uploaded_file[0]  # Get the first item (since there's only one file)\n",
    "\n",
    "        # Now uploaded_file is a dictionary with keys as filenames\n",
    "        for filename, file_info in uploaded_file.items():\n",
    "            # Debugging: Check the type of file_info\n",
    "            print(f\"Debug: File info type: {type(file_info)}\")\n",
    "            print(f\"Debug: File info content: {file_info}\")\n",
    "            \n",
    "            # Handle unexpected types\n",
    "            if isinstance(file_info, dict):\n",
    "                file_content = file_info['content']  # Extract file content\n",
    "            elif isinstance(file_info, str):\n",
    "                # If it's a string, treat it as the content directly\n",
    "                file_content = file_info.encode()  # Convert the string content to bytes\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected file_info format: {type(file_info)}\")\n",
    "\n",
    "            # Ensure the saved file has a .jpg extension, regardless of the uploaded file's extension\n",
    "            file_path = os.path.join(upload_directory, f\"{os.path.splitext(filename)[0]}.jpg\")\n",
    "            \n",
    "            # Show progress bar during saving\n",
    "            loading_bar.value = 0  # Reset progress bar to 0 before uploading\n",
    "            \n",
    "            # Simulate the upload process (you can remove this simulation in production)\n",
    "            for i in range(1, 101):\n",
    "                time.sleep(0.05)  # Simulate some delay during the upload\n",
    "                loading_bar.value = i  # Update the progress bar\n",
    "            \n",
    "            # Save the file content to the specified file path\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(file_content)  # Write the file content as bytes\n",
    "            \n",
    "            # Update progress bar to 100% when finished\n",
    "            loading_bar.value = 100  # Set it to 100% when upload is complete\n",
    "            print(f\"File saved successfully at: {file_path}\")\n",
    "            print(f\"File name: {filename}\")\n",
    "            \n",
    "            # Display the file content (for verification purposes)\n",
    "            print(f\"File Content (First 100 bytes): {file_content[:100]}\")  # Display first 100 bytes of content\n",
    "            print(f\"File size: {len(file_content)} bytes\")  # Display file size\n",
    "            \n",
    "            # Hide the progress bar after a brief moment\n",
    "            time.sleep(1)\n",
    "            loading_bar.layout.visibility = 'hidden'  # Hide the progress bar after completion\n",
    "\n",
    "# Bind the save function to the widget's value change event\n",
    "upload.observe(save_uploaded_file, names='value')\n",
    "\n",
    "# Display the widgets\n",
    "display(upload_button)\n",
    "display(upload)\n",
    "display(loading_bar)\n",
    "\n",
    "# Initially, the file upload widget is hidden, and only the \"Select Image to Upload\" button is visible\n",
    "upload.layout.visibility = 'hidden'  # Hide the file upload widget initially\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca2f396-8a70-4058-83a3-56dfb9b106be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lastname firstname  articleNum   birthDate  birthMonth  birthDay     zodiac\n",
      "0  Aaliyah       NaN           0  1979-01-16         1.0      16.0  Capricorn\n",
      "1    Aaron      Hank          46  1934-02-05         2.0       5.0   Aquarius\n",
      "2   Abacha      Sani           2  1943-09-20         9.0      20.0      Virgo\n",
      "3   Abbado   Claudio           9  1933-06-26         6.0      26.0     Cancer\n",
      "4    Abbas   Mahmoud         306  1935-03-26         3.0      26.0      Aries\n",
      "lastname      0\n",
      "firstname     0\n",
      "articleNum    0\n",
      "birthDate     0\n",
      "birthMonth    0\n",
      "birthDay      0\n",
      "zodiac        0\n",
      "dtype: int64\n",
      "Predicted zodiac sign: Capricorn\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer  # For imputing missing values\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "data_path = r\"C:\\Users\\BineshMahato\\.cache\\kagglehub\\datasets\\mexwell\\famous-birthdays\\versions\\2\\birthdays.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display the first few rows of the dataset to check its structure\n",
    "print(df.head())\n",
    "\n",
    "# Handle missing values (impute numeric columns)\n",
    "imputer = SimpleImputer(strategy='most_frequent')  # Use most frequent value for categorical data\n",
    "df[['firstname', 'birthDate', 'birthMonth', 'birthDay', 'zodiac']] = imputer.fit_transform(df[['firstname', 'birthDate', 'birthMonth', 'birthDay', 'zodiac']])\n",
    "\n",
    "# Verify missing values are handled\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Encode the 'zodiac' column as categorical data\n",
    "df['zodiac'] = pd.Categorical(df['zodiac'])\n",
    "df['zodiac_code'] = df['zodiac'].cat.codes\n",
    "\n",
    "# Convert 'birthMonth' to numeric value\n",
    "df['birthMonth'] = pd.to_datetime(df['birthMonth'], errors='coerce').dt.month\n",
    "\n",
    "# Drop any rows with missing values in 'birthMonth'\n",
    "df = df.dropna(subset=['birthMonth'])\n",
    "\n",
    "# Now, let's use 'birthMonth' as a feature for prediction\n",
    "X = df[['birthMonth']]  # Feature: birthMonth\n",
    "y = df['zodiac_code']  # Target: zodiac_code\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Example input: Let's predict the zodiac sign based on the birth month '5' (May)\n",
    "input_data = pd.DataFrame([[5]], columns=['birthMonth'])\n",
    "\n",
    "# Predict the zodiac (output will be in numeric code)\n",
    "predicted_zodiac_code = model.predict(input_data)\n",
    "\n",
    "# Convert numeric prediction back to original zodiac category\n",
    "inverse_prediction = df['zodiac'].cat.categories[predicted_zodiac_code][0]\n",
    "print(f'Predicted zodiac sign: {inverse_prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96766897-8cf7-464f-af14-8702dae82d00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy birthday to My friend.\n",
      "\n",
      "You might have noticed that my first email to you is a question that I asked myself, and it's an obvious one:\n",
      ". . .\n",
      "â€¦\n",
      "\"What's the point in having to deal with this kind of thing?\"\n",
      ": . I'm just not a fan of this. And I don't like it at all. So let me tell you something: I've always been a big fan. I think it is the best way to have\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "# Encode input text\n",
    "input_text = \"Happy birthday to My friend.\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate text with adjusted parameters\n",
    "output = model.generate(\n",
    "    inputs[\"input_ids\"], \n",
    "    max_length=100, \n",
    "    num_return_sequences=1, \n",
    "    no_repeat_ngram_size=2,  # Prevent repeating 2-grams\n",
    "    temperature=0.7,  # Control randomness\n",
    "    top_p=0.9,  # Nucleus sampling\n",
    "    top_k=50,  # Top-k sampling, limit to the top 50 tokens\n",
    "    do_sample=True  # Use sampling instead of greedy generation\n",
    ")\n",
    "\n",
    "# Decode the generated text\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d050141-4956-49eb-aa82-1d68251bb3ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy Birthday, Capricorn! Wishing you success in your career and happiness in your life. You love your job. And in your heart, your heart! In your spirit, Capricorn! You will protect our country so we can live peacefully together and honor your family. I love you, Capricorn. I love you, Capricorn, very much.\n",
      "\n",
      "Your gift will be given to me. Now, Capricorn! I love you, Capricorn.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Since the model and tokenizer have already been loaded:\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "# Create the text-generation pipeline\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Load the dataset from the CSV file (you can use it later for more personalization)\n",
    "data_path = r\"C:\\Users\\BineshMahato\\.cache\\kagglehub\\datasets\\mexwell\\famous-birthdays\\versions\\2\\birthdays.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Assuming you know the user's birth month and want to predict the zodiac sign\n",
    "user_birth_month = 1  # Example: May\n",
    "\n",
    "# Zodiac map based on the birth month\n",
    "zodiac_map = {\n",
    "    1: 'Capricorn', 2: 'Aquarius', 3: 'Pisces', 4: 'Aries', 5: 'Taurus',\n",
    "    6: 'Gemini', 7: 'Cancer', 8: 'Leo', 9: 'Virgo', 10: 'Libra',\n",
    "    11: 'Scorpio', 12: 'Sagittarius'\n",
    "}\n",
    "\n",
    "# Get the zodiac sign based on birth month\n",
    "user_zodiac_sign = zodiac_map[user_birth_month]\n",
    "\n",
    "# Create the input prompt using the zodiac sign\n",
    "user_input = f\"Happy Birthday, {user_zodiac_sign}! Wishing you success in your career and happiness in your life.\"\n",
    "\n",
    "# Generate a personalized birthday message using GPT-2\n",
    "generated_message = generator(user_input, max_length=100, num_return_sequences=1)\n",
    "\n",
    "# Print the generated birthday message\n",
    "print(generated_message[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7fc09281-fca9-4322-a820-394cc1cccdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time capsule saved successfully with the photo and content.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import json\n",
    "\n",
    "# Load GPT-2 model\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Function to generate personalized birthday message\n",
    "def generate_birthday_message(name):\n",
    "    prompt = f\"Write a birthday message for {name}:\"\n",
    "    message = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "    return message[0]['generated_text']\n",
    "\n",
    "# Function to generate future prediction\n",
    "def generate_prediction(name):\n",
    "    prompt = f\"Write a prediction for {name} in 10 years:\"\n",
    "    prediction = generator(prompt, max_length=150, num_return_sequences=1)\n",
    "    return prediction[0]['generated_text']\n",
    "\n",
    "# Photo path (you can replace this with the actual path of the uploaded image)\n",
    "photo_path = \"memory_2.jpeg\"  # Replace with actual path\n",
    "\n",
    "# Generate personalized content\n",
    "name = \"Binesh\"  \n",
    "birthday_message = generate_birthday_message(name)\n",
    "prediction = generate_prediction(name)\n",
    "\n",
    "\n",
    "# Collecting data into a dictionary\n",
    "capsule_data = {\n",
    "    'memories': [photo_path],  # Add the photo path\n",
    "    'predictions': prediction,\n",
    "    'birthday_message': birthday_message,\n",
    "}\n",
    "\n",
    "# Saving the time capsule data as a JSON file\n",
    "with open('time_capsule.json', 'w') as json_file:\n",
    "    json.dump(capsule_data, json_file)\n",
    "\n",
    "print(\"Time capsule saved successfully with the photo and content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c600c06d-20c0-479d-a380-be475f7a47d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birthday Message: Write a birthday message for Binesh:\n",
      "\n",
      "<b>Binesh</b>\n",
      "\n",
      "Then\n",
      "\n",
      "<string> \"</string>\n",
      "\n",
      "When you press <c,c>on</c>, select any letter and\n",
      "Prediction: Write a prediction for Binesh in 10 years:\n",
      "\n",
      "if (i.e. (I.e. we'll have a 10 year chance, or if he can actually do that to the people who make things in his life like not getting raped? We know he will, but why would he want to do that now when they haven't raped him? Why do we care if he's going to survive and his life in general would really be a mess for the next decade if that all changed?)\n",
      "\n",
      "There are ways you can take one idea from the present and rewrite it to avoid a future that seems more like 100% predictable. Let's make a prediction about whether P-K can survive the B2B and if it\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# Load the time capsule data from the JSON file\n",
    "with open('time_capsule.json', 'r') as json_file:\n",
    "    capsule_data = json.load(json_file)\n",
    "\n",
    "# Extract the data\n",
    "photo_path = capsule_data['memories'][0]\n",
    "birthday_message = capsule_data['birthday_message']\n",
    "prediction = capsule_data['predictions']\n",
    "\n",
    "# Display the image using PIL\n",
    "img = Image.open(photo_path)\n",
    "img.show()  # This will open the photo in the default viewer\n",
    "\n",
    "# Print the generated content\n",
    "print(f\"Birthday Message: {birthday_message}\")\n",
    "print(f\"Prediction: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2144c1a5-d030-47b7-82d1-af5cc37eb03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "# Load memory images\n",
    "memory_images = ['memory_1.jpg', 'memory_2.jpeg']  # Replace with actual file paths\n",
    "images = [Image.open(img_path) for img_path in memory_images]\n",
    "\n",
    "# Create a blank white image for the canvas\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "canvas = Image.new('RGB', (canvas_width, canvas_height), color='white')\n",
    "draw = ImageDraw.Draw(canvas)\n",
    "\n",
    "# Resize images to fit within the canvas\n",
    "image_width = int(canvas_width / 2)\n",
    "image_height = int(canvas_height / 2)\n",
    "resized_images = [img.resize((image_width, image_height)) for img in images]\n",
    "\n",
    "# Paste images onto the canvas (side by side)\n",
    "x_offset = 0\n",
    "for img in resized_images:\n",
    "    canvas.paste(img, (x_offset, 0))\n",
    "    x_offset += image_width\n",
    "\n",
    "# Add the generated prediction and birthday message text\n",
    "font = ImageFont.load_default()  # You can use a custom font file if needed\n",
    "text_margin = 10\n",
    "\n",
    "# Add the prediction text\n",
    "draw.text((text_margin, canvas_height - 100), prediction, fill='black', font=font)\n",
    "# Add the birthday message text\n",
    "draw.text((text_margin, canvas_height - 40), birthday_message, fill='black', font=font)\n",
    "\n",
    "# Save or display the time capsule image\n",
    "canvas.save('time_capsule_image.jpg')  # Save the image\n",
    "canvas.show()  # Display the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7d007-d840-4f1c-93b4-300d90eb43c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data: Career progression prediction over years\n",
    "years = [2024, 2025, 2026, 2027]\n",
    "predictions = ['Engineer', 'Manager', 'Lead Engineer', 'Director']\n",
    "\n",
    "plt.plot(years, predictions, marker='o')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Career Progression')\n",
    "plt.title('Career Progression Over Time')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9c9be-8699-4950-989d-9022c2921378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
